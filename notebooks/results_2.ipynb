{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmourit/Documents/0project/MScThesis/notebooks\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from ggplot import *\n",
    "import json\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "print('Current directory: {}'.format(os.getcwd()))\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "DATA_PATH = '../../bucket/data/'\n",
    "RESULTS_PATH = '../../bucket/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latex stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "\n",
    "def mean_pm_std(mean, std):\n",
    "    return '{:1.2f}$\\pm${:1.2f}'.format(mean, std)\n",
    "mean_pm_std = np.vectorize(mean_pm_std)\n",
    "\n",
    "def pbcopy(data): \n",
    "    p = subprocess.Popen(['pbcopy'], stdin=subprocess.PIPE) \n",
    "    p.stdin.write(data) \n",
    "    p.stdin.close() \n",
    "    retcode = p.wait()    \n",
    "\n",
    "def bold_center(cell):\n",
    "    return r'\\mc{1}{c}{\\textbf{' + cell + '}}'\n",
    "\n",
    "def process_latex(tabular, remove_lines=None):\n",
    "    if remove_lines and not isinstance(remove_lines, list):\n",
    "        remove_lines = [remove_lines]\n",
    "    \n",
    "    purged_tabular = []\n",
    "    for line in tabular.split('\\n'):\n",
    "        if r'\\begin{tabular}' in line:\n",
    "            begin_tabular = line.split('}{')\n",
    "            line = begin_tabular[0] + '}'\n",
    "            line += '{' + begin_tabular[1].replace('l', 'r')\n",
    "            purged_tabular.append(line)\n",
    "        elif remove_lines and not any(re.match(pattern, line) for pattern in remove_lines):\n",
    "            purged_tabular.append(line)\n",
    "    tabular = '\\n'.join(purged_tabular)\n",
    "        \n",
    "    table_env_begin = r\"\"\"\\begin{table}[!h]\n",
    "                       \\centering\n",
    "                       \\footnotesize\n",
    "                       \"\"\".replace(' ', '')\n",
    "    table_env_end = r\"\"\"\\caption{caption:placeholder}\n",
    "                     \\label{tab:placeholder}\n",
    "                     \\end{table}\n",
    "                     \"\"\".replace(' ', '')\n",
    "    \n",
    "    return table_env_begin + tabular + table_env_end\n",
    "    \n",
    "CAPTION_PLACEHOLDER = r'caption:placeholder'\n",
    "REMOVE_N_FEATURES = r'^n\\\\_features*'\n",
    "\n",
    "TABLES_FOLDER = '~/Dropbox/MSc Thesis/tables'\n",
    "\n",
    "def save_table(tex, filename, caption=None, folder=TABLES_FOLDER):\n",
    "    folder = os.path.expanduser(folder)\n",
    "    tex = tex.replace('tab:placeholder', 'tab:{}'.format(filename.split('.')[0]))\n",
    "    if caption is not None:\n",
    "        tex = tex.replace(CAPTION_PLACEHOLDER, caption)\n",
    "    with open(os.path.join(folder, filename), 'w') as f:\n",
    "        f.write(tex)\n",
    "        \n",
    "def my_replace(tex, name=None, src=None, dst=None, effects=None):\n",
    "    name_map = {\n",
    "        'en': (' en ', 'EN'),\n",
    "        'svm': ('svm\\_linear\\_kernel', 'SVM'),\n",
    "        'svm k': ('svm\\_linear', 'SVM'),\n",
    "        'l1 svm': ('svm\\_linear\\_l1', 'L1-SVM'),\n",
    "        'clf': ('clf', 'CLF'),\n",
    "        'pm': (r'\\$\\textbackslashpm\\$', r'$\\pm$'),\n",
    "        'IG1': (r'infogain\\_10', 'IG D1'),\n",
    "        'IG2': (r'infogain\\_exp', 'IG D2'),\n",
    "        'anova': ('anova', 'ANOVA'),\n",
    "        'mrmr': ('mrmr', 'mRMR'),\n",
    "        'rfe': ('rfe', 'RFE'),\n",
    "        'chi2': ('chi2', 'Chi2'),\n",
    "        'stg': ('superior temporal gyrus', 'STG'),\n",
    "        'wb': ('whole blood', 'WB'),\n",
    "        'cer': ('cerebellum', 'CER'),\n",
    "        'fc': ('frontal cortex', 'FC'),\n",
    "        'ec': ('entorhinal cortex', 'EC')\n",
    "    }\n",
    "    \n",
    "    effects_map = {\n",
    "        '2': r'\\mc{2}{c}{%s}',\n",
    "        '2r': r'\\multirow{2}{*}{%s}',\n",
    "        '3r': r'\\multirow{3}{*}{%s}',\n",
    "        'b': r'\\textbf{%s}',\n",
    "        'c': r'\\mc{1}{c}{%s}'\n",
    "    }\n",
    "    \n",
    "    if name is not None:\n",
    "        src = name_map[name][0]\n",
    "        dst = name_map[name][1]\n",
    "    \n",
    "    if effects is not None:\n",
    "        \n",
    "        for effect in effects:\n",
    "            dst = effects_map[effect] % dst\n",
    "        \n",
    "    return tex.replace(src, dst)     \n",
    "        \n",
    "def batch_replace(tex, replacements):\n",
    "    for name, effects in replacements:\n",
    "        tex = my_replace(tex, name=name, effects=effects)\n",
    "    return tex\n",
    "\n",
    "def add_clines(tex, clines):\n",
    "    if not isinstance(clines, list):\n",
    "        clines = iter([clines])\n",
    "    else:\n",
    "        clines = iter(clines)\n",
    "    \n",
    "    new_tex = []\n",
    "    l, a, b = next(clines)\n",
    "    i = 0\n",
    "    for line in tex.split('\\n'):\n",
    "        new_tex.append(line)\n",
    "        if line.endswith(r'\\\\'):\n",
    "            i += 1\n",
    "        rules = ''\n",
    "        while l == i:\n",
    "            rules += r'\\cmidrule(rl){%d-%d}' % (a, b)\n",
    "            try:\n",
    "                l, a, b = next(clines)\n",
    "            except StopIteration:\n",
    "                l = -1\n",
    "        if rules:\n",
    "            new_tex.append(rules)\n",
    "    \n",
    "    return '\\n'.join(new_tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MDD = 'mdd_raw37'\n",
    "EPI = 'epi_ad'\n",
    "AD = 'ad.disease.status'\n",
    "\n",
    "STG = 'superior temporal gyrus'\n",
    "WB = 'whole blood'\n",
    "CER = 'cerebellum'\n",
    "FC = 'frontal cortex'\n",
    "EC = 'entorhinal cortex'\n",
    "\n",
    "LIN_SVM = 'svm_linear'\n",
    "KER_SVM = 'svm_linear_kernel'\n",
    "L1_SVM = 'svm_linear_l1'\n",
    "\n",
    "GOOD_CLF_FILTER = (\"(clf == 'en' & filter == ['rfe', 'chi2', 'infogain_exp']) \"\n",
    "                   \"| (clf == ['svm_linear', 'svm_linear_kernel'] \"\n",
    "                      \"& filter == ['anova', 'rfe', 'infogain_10', 'mrmr', 'chi2'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../bucket/results/anova_-800824884543483809.json -> Field \"subsets\" not found.\n",
      "../../bucket/results/anova_1773782541069684787.json -> Field \"subsets\" not found.\n",
      "../../bucket/results/infogain_10_2347697712435705707.json -> Field \"subsets\" not found.\n",
      "../../bucket/results/infogain_exp_-905003234740235046.json -> Field \"subsets\" not found.\n",
      "../../bucket/results/infogain_exp_7158626770039509150.json -> Field \"subsets\" not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "result_files = glob(join(RESULTS_PATH, '*_*.json'))\n",
    "result_files = [x for x in result_files if os.path.basename(x).startswith(('anova', 'infogain', 'rfe', 'chi2', 'mrmr'))]\n",
    "\n",
    "results = []\n",
    "for f in result_files:\n",
    "    exp_id = f.split('_')[-1].rstrip('.json')\n",
    "    try:\n",
    "        d = json.load(open(join(RESULTS_PATH, f), 'r'))\n",
    "    except ValueError as e:\n",
    "        if os.path.getsize(f) == 0:\n",
    "            e = 'File size is 0. Removing.'\n",
    "            os.remove(f)\n",
    "        print('{} -> {}'.format(f, e))\n",
    "    base = {'exp_id': exp_id}\n",
    "    left = []\n",
    "    for k, v in d.items():\n",
    "        if k != 'experiments':\n",
    "            base[k] = v\n",
    "    if os.path.basename(f).startswith('mrmr'):\n",
    "        base['filter'] = 'mrmr'\n",
    "    elif os.path.basename(f).startswith('rfe'):\n",
    "        base['filter'] = 'rfe'\n",
    "    for exp in d['experiments']:\n",
    "        it = exp['iteration']\n",
    "        if 'subsets' not in exp:\n",
    "            print('{} -> Field \"subsets\" not found.'.format(f))\n",
    "            continue\n",
    "        for s in exp['subsets']:\n",
    "            train = accuracy_score(s['train']['y_true'], s['train']['y_pred'])\n",
    "            test = accuracy_score(s['test']['y_true'], s['test']['y_pred'])\n",
    "            if 'n_features' in s:\n",
    "                n_features = s['n_features']\n",
    "            else:\n",
    "                n_features = len(s['features'])   \n",
    "            results.append(dict(base, iteration=it, train=train, test=test, n_features=n_features))    \n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_distance(a, b):\n",
    "    if not isinstance(a, set):\n",
    "        a = set(a)\n",
    "    if not isinstance(b, set):\n",
    "        b = set(b)\n",
    "    union_size = len(a | b)\n",
    "    inter_size = len(a & b)\n",
    "    return (union_size - inter_size) / union_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1 31\n",
      "36 2 34\n",
      "370 3 357\n",
      "423 4 409\n",
      "458 5 443\n",
      "0:12:42.236835\n",
      "760 5 745\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "result_files = glob(join(RESULTS_PATH, '*_*.json'))\n",
    "result_files = [x for x in result_files if os.path.basename(x).startswith(('anova', 'infogain', 'rfe', 'chi2', 'mrmr'))]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# clf = 'svm'\n",
    "# filter_ = 'anova'\n",
    "# data = MDD\n",
    "# target = 'stress'\n",
    "\n",
    "# constraints = [('clf', KER_SVM), ('filter', 'infogain_10'), ('data', MDD), ('target', 'stress')]\n",
    "constraints = [('clf', 'en'), ('filter', 'chi2'), ('data', EPI), ('tissue', WB)]\n",
    "keyby = ['n_features']\n",
    "i = 0\n",
    "no_clf = 0\n",
    "no_cond = 0\n",
    "results = defaultdict(list)\n",
    "\n",
    "d0 = datetime.now()\n",
    "for f in result_files:\n",
    "    i += 1\n",
    "    exp_id = f.split('_')[-1].rstrip('.json')\n",
    "    try:\n",
    "        d = json.load(open(join(RESULTS_PATH, f), 'r'))\n",
    "    except ValueError as e:\n",
    "        if os.path.getsize(f) == 0:\n",
    "            e = 'File size is 0. Removing.'\n",
    "            os.remove(f)\n",
    "        print('{} -> {}'.format(f, e))\n",
    "        os.remove(f)\n",
    "    base = {'exp_id': exp_id}\n",
    "    left = []\n",
    "    for k, v in d.items():\n",
    "        if k != 'experiments':\n",
    "            base[k] = v\n",
    "    if os.path.basename(f).startswith('mrmr'):\n",
    "        base['filter'] = 'mrmr'\n",
    "    elif os.path.basename(f).startswith('rfe'):\n",
    "        base['filter'] = 'rfe'\n",
    "  \n",
    "    if 'clf' not in base:\n",
    "        no_clf += 1\n",
    "        print(i, no_clf, no_cond)\n",
    "        continue\n",
    "        \n",
    "    if not all(base[k] == v for k, v in constraints):\n",
    "        no_cond += 1\n",
    "        continue\n",
    "        \n",
    "    for exp in d['experiments']:\n",
    "        it = exp['iteration']\n",
    "        if 'subsets' not in exp:\n",
    "            print('{} -> Field \"subsets\" not found.'.format(f))\n",
    "            continue\n",
    "        for s in exp['subsets']:\n",
    "            if 'n_features' not in s:\n",
    "                s['n_features'] = len(s['features'])\n",
    "            key = tuple(base[x] if x in base else s[x] for x in keyby)\n",
    "            results[key].append(set(s['features']))\n",
    "\n",
    "print(datetime.now() - d0)\n",
    "print(i, no_clf, no_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 s, sys: 1.53 s, total: 38.4 s\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import combinations\n",
    "\n",
    "MDD_SIZES = [485577, 200000, 100000, 50000, 10000, 5000, 1000, 500, 100, 10]\n",
    "\n",
    "robust = defaultdict(dict)\n",
    "for k in results:\n",
    "    n_feat, = k\n",
    "    if n_feat not in MDD_SIZES:\n",
    "        continue\n",
    "    ss = results[k]\n",
    "    union = set()\n",
    "    inter = ss[0]\n",
    "    for s in ss:\n",
    "        union |= s\n",
    "        inter &= s\n",
    "    robust[n_feat]['union'] = union\n",
    "    robust[n_feat]['inter'] = inter\n",
    "    jac = 0.0\n",
    "    n = 0\n",
    "    for i, j in combinations(xrange(len(ss)), 2):\n",
    "        jac += jaccard_distance(ss[i], ss[j])\n",
    "        n += 1\n",
    "    jac /= n\n",
    "    robust[n_feat]['jaccard'] = jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SOMEWHERE = '../../selection/'\n",
    "from os.path import join\n",
    "import cPickle as pickle\n",
    "\n",
    "# FILES = ['mdd_svm_anova.json', 'mdd_svm_mrmr.json', 'mdd_svm_infogain_10.json']\n",
    "FILE1 = 'ad_ec_en_chi2.json'\n",
    "FILE2 = 'ad_fc_svm_infogain_10.json'\n",
    "FILE3 = 'ad_wb_en_chi2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(robust, open(join(SOMEWHERE, FILE3), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = pickle.load(open(join(SOMEWHERE, FILE3), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000, 200000, 100, 5000, 485577, 10, 50000, 1000, 500, 10000]"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def robust_to_list_of_dicts(robust, clf, filter_):\n",
    "     return[{'clf': clf, 'filter': filter_, 'union': len(v['union']), 'inter': len(v['inter']), 'jaccard': v['jaccard'], 'size': k} for k, v in robust.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 26783,\n",
       "  'jaccard': 0.5705458560390116,\n",
       "  'size': 100000,\n",
       "  'union': 223182},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 74623,\n",
       "  'jaccard': 0.4663780811346781,\n",
       "  'size': 200000,\n",
       "  'union': 359554},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 5,\n",
       "  'jaccard': 0.8285991033448942,\n",
       "  'size': 100,\n",
       "  'union': 448},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 571,\n",
       "  'jaccard': 0.7530691850919499,\n",
       "  'size': 5000,\n",
       "  'union': 18090},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 485577,\n",
       "  'jaccard': 0.0,\n",
       "  'size': 485577,\n",
       "  'union': 485577},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 0,\n",
       "  'jaccard': 0.9165099568092339,\n",
       "  'size': 10,\n",
       "  'union': 57},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 10297,\n",
       "  'jaccard': 0.6372671043657417,\n",
       "  'size': 50000,\n",
       "  'union': 130681},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 83,\n",
       "  'jaccard': 0.79544437721945,\n",
       "  'size': 1000,\n",
       "  'union': 4079},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 38,\n",
       "  'jaccard': 0.8063268203188548,\n",
       "  'size': 500,\n",
       "  'union': 2145},\n",
       " {'clf': 'ec en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 1325,\n",
       "  'jaccard': 0.7295330429256197,\n",
       "  'size': 10000,\n",
       "  'union': 33487},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 23202,\n",
       "  'jaccard': 0.5976995649593441,\n",
       "  'size': 100000,\n",
       "  'union': 237819},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 71169,\n",
       "  'jaccard': 0.47194217344979145,\n",
       "  'size': 200000,\n",
       "  'union': 361948},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 6,\n",
       "  'jaccard': 0.8552142138417206,\n",
       "  'size': 100,\n",
       "  'union': 525},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 502,\n",
       "  'jaccard': 0.7767478275347126,\n",
       "  'size': 5000,\n",
       "  'union': 20104},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 485577,\n",
       "  'jaccard': 0.0,\n",
       "  'size': 485577,\n",
       "  'union': 485577},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 0,\n",
       "  'jaccard': 0.866680044337423,\n",
       "  'size': 10,\n",
       "  'union': 51},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 8582,\n",
       "  'jaccard': 0.6704641671294405,\n",
       "  'size': 50000,\n",
       "  'union': 143783},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 72,\n",
       "  'jaccard': 0.8208734993769876,\n",
       "  'size': 1000,\n",
       "  'union': 4574},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 28,\n",
       "  'jaccard': 0.8369171275540612,\n",
       "  'size': 500,\n",
       "  'union': 2441},\n",
       " {'clf': 'fc svm',\n",
       "  'filter': 'infogain_10',\n",
       "  'inter': 1134,\n",
       "  'jaccard': 0.75648649331549,\n",
       "  'size': 10000,\n",
       "  'union': 37417},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 25919,\n",
       "  'jaccard': 0.5895556476139184,\n",
       "  'size': 100000,\n",
       "  'union': 232786},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 72738,\n",
       "  'jaccard': 0.48384771815332833,\n",
       "  'size': 200000,\n",
       "  'union': 368988},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 3,\n",
       "  'jaccard': 0.8837007722606914,\n",
       "  'size': 100,\n",
       "  'union': 535},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 476,\n",
       "  'jaccard': 0.7827548104661417,\n",
       "  'size': 5000,\n",
       "  'union': 19542},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 485577,\n",
       "  'jaccard': 0.0,\n",
       "  'size': 485577,\n",
       "  'union': 485577},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 0,\n",
       "  'jaccard': 0.9550128043420091,\n",
       "  'size': 10,\n",
       "  'union': 68},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 9878,\n",
       "  'jaccard': 0.6574686521110975,\n",
       "  'size': 50000,\n",
       "  'union': 137432},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 61,\n",
       "  'jaccard': 0.8346272652644952,\n",
       "  'size': 1000,\n",
       "  'union': 4592},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 23,\n",
       "  'jaccard': 0.851714409973431,\n",
       "  'size': 500,\n",
       "  'union': 2420},\n",
       " {'clf': 'wb en',\n",
       "  'filter': 'chi2',\n",
       "  'inter': 1201,\n",
       "  'jaccard': 0.7525814175860644,\n",
       "  'size': 10000,\n",
       "  'union': 35704}]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = []\n",
    "foo += robust_to_list_of_dicts(pickle.load(open(join(SOMEWHERE, FILE1), 'r')), 'ec en', 'chi2')\n",
    "foo += robust_to_list_of_dicts(pickle.load(open(join(SOMEWHERE, FILE2), 'r')), 'fc svm', 'infogain_10')\n",
    "foo += robust_to_list_of_dicts(pickle.load(open(join(SOMEWHERE, FILE3), 'r')), 'wb en', 'chi2')\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>clf</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ec en</th>\n",
       "      <th colspan=\"3\" halign=\"left\">fc svm</th>\n",
       "      <th colspan=\"3\" halign=\"left\">wb en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filter</th>\n",
       "      <th colspan=\"3\" halign=\"left\">chi2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">infogain_10</th>\n",
       "      <th colspan=\"3\" halign=\"left\">chi2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>inter</th>\n",
       "      <th>union</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>inter</th>\n",
       "      <th>union</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>inter</th>\n",
       "      <th>union</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485577</th>\n",
       "      <td>485577</td>\n",
       "      <td>485577</td>\n",
       "      <td>0.00</td>\n",
       "      <td>485577</td>\n",
       "      <td>485577</td>\n",
       "      <td>0.00</td>\n",
       "      <td>485577</td>\n",
       "      <td>485577</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>74623</td>\n",
       "      <td>359554</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71169</td>\n",
       "      <td>361948</td>\n",
       "      <td>0.47</td>\n",
       "      <td>72738</td>\n",
       "      <td>368988</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>26783</td>\n",
       "      <td>223182</td>\n",
       "      <td>0.57</td>\n",
       "      <td>23202</td>\n",
       "      <td>237819</td>\n",
       "      <td>0.60</td>\n",
       "      <td>25919</td>\n",
       "      <td>232786</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>10297</td>\n",
       "      <td>130681</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8582</td>\n",
       "      <td>143783</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9878</td>\n",
       "      <td>137432</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1325</td>\n",
       "      <td>33487</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1134</td>\n",
       "      <td>37417</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1201</td>\n",
       "      <td>35704</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>571</td>\n",
       "      <td>18090</td>\n",
       "      <td>0.75</td>\n",
       "      <td>502</td>\n",
       "      <td>20104</td>\n",
       "      <td>0.78</td>\n",
       "      <td>476</td>\n",
       "      <td>19542</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>83</td>\n",
       "      <td>4079</td>\n",
       "      <td>0.80</td>\n",
       "      <td>72</td>\n",
       "      <td>4574</td>\n",
       "      <td>0.82</td>\n",
       "      <td>61</td>\n",
       "      <td>4592</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>38</td>\n",
       "      <td>2145</td>\n",
       "      <td>0.81</td>\n",
       "      <td>28</td>\n",
       "      <td>2441</td>\n",
       "      <td>0.84</td>\n",
       "      <td>23</td>\n",
       "      <td>2420</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>448</td>\n",
       "      <td>0.83</td>\n",
       "      <td>6</td>\n",
       "      <td>525</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3</td>\n",
       "      <td>535</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "clf      ec en                      fc svm                   wb en          \\\n",
       "filter    chi2                 infogain_10                    chi2           \n",
       "         inter   union jaccard       inter   union jaccard   inter   union   \n",
       "size                                                                         \n",
       "485577  485577  485577    0.00      485577  485577    0.00  485577  485577   \n",
       "200000   74623  359554    0.47       71169  361948    0.47   72738  368988   \n",
       "100000   26783  223182    0.57       23202  237819    0.60   25919  232786   \n",
       "50000    10297  130681    0.64        8582  143783    0.67    9878  137432   \n",
       "10000     1325   33487    0.73        1134   37417    0.76    1201   35704   \n",
       "5000       571   18090    0.75         502   20104    0.78     476   19542   \n",
       "1000        83    4079    0.80          72    4574    0.82      61    4592   \n",
       "500         38    2145    0.81          28    2441    0.84      23    2420   \n",
       "100          5     448    0.83           6     525    0.86       3     535   \n",
       "10           0      57    0.92           0      51    0.87       0      68   \n",
       "\n",
       "clf             \n",
       "filter          \n",
       "       jaccard  \n",
       "size            \n",
       "485577    0.00  \n",
       "200000    0.48  \n",
       "100000    0.59  \n",
       "50000     0.66  \n",
       "10000     0.75  \n",
       "5000      0.78  \n",
       "1000      0.83  \n",
       "500       0.85  \n",
       "100       0.88  \n",
       "10        0.96  "
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_jaccard(jaccard):\n",
    "    return '{:0.2f}'.format(jaccard)\n",
    "format_jaccard = np.vectorize(format_jaccard)\n",
    "\n",
    "df = pd.DataFrame(foo)\n",
    "df['jaccard'] = format_jaccard(df['jaccard'])\n",
    "## df = df.groupby(['filter', 'size'])\n",
    "# df = df.drop('clf', axis=1)\n",
    "## df = df.groupby(['filter'])\n",
    "## df = df.unstack('filter')\n",
    "df = df.set_index(['clf', 'filter', 'size']).unstack('clf').unstack('filter')\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df = df.swaplevel(0, 2, axis=1)\n",
    "df = df.swaplevel(0, 1, axis=1)\n",
    "# df = df[[('anova', 'inter'), ('anova', 'union'), ('anova', 'jaccard'),\n",
    "#          ('mrmr', 'inter'), ('mrmr', 'union'), ('mrmr', 'jaccard'),\n",
    "#          ('infogain_10', 'inter'), ('infogain_10', 'union'), ('infogain_10', 'jaccard')]]\n",
    "df = df[[('ec en', 'chi2', 'inter'), ('ec en', 'chi2', 'union'), ('ec en', 'chi2', 'jaccard'),\n",
    "         ('fc svm', 'infogain_10', 'inter'), ('fc svm', 'infogain_10', 'union'), ('fc svm', 'infogain_10', 'jaccard'),\n",
    "         ('wb en', 'chi2', 'inter'), ('wb en', 'chi2', 'union'), ('wb en', 'chi2', 'jaccard')]]\n",
    "df = df.iloc[::-1]\n",
    "foo_latex = df.to_latex(na_rep=' ')\n",
    "foo_latex = process_latex(foo_latex, remove_lines=r'^size*')\n",
    "repl = [\n",
    "#     ('clf', ['b', '3r', 'c']),\n",
    "#         ('en', 'bc'),\n",
    "#         ('svm', 'bc'),\n",
    "#         ('l1 svm', 'bc'),\n",
    "        ('IG1', 'bc'),\n",
    "        ('IG2', 'bc'),\n",
    "        ('anova', 'bc'), ('mrmr', 'bc'),\n",
    "        ('chi2', 'bc'), \n",
    "        ('pm', None)]\n",
    "foo_latex = batch_replace(foo_latex, repl)\n",
    "foo_latex = foo_latex.replace('filter', '')\n",
    "foo_latex = my_replace(foo_latex, src='clf', dst='\\# Feat', effects=['b', '2r', 'c'])\n",
    "foo_latex = my_replace(foo_latex, src='inter', dst=r'$\\bm{\\cap}$', effects='c')\n",
    "foo_latex = my_replace(foo_latex, src='union', dst=r'$\\bm{\\cup}$', effects='c')\n",
    "foo_latex = my_replace(foo_latex, src='jaccard', dst=r'$\\bm{J}$', effects='c')\n",
    "foo_latex = add_clines(foo_latex, [(2, 2, 4), (2, 5, 7), (2, 8, 10)])\n",
    "save_table(foo_latex, 'ad_robust.tex')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# anova = pickle.load(open(join(SOMEWHERE, 'mdd_svm_anova.json'), 'r'))\n",
    "# mrmr = pickle.load(open(join(SOMEWHERE, 'mdd_svm_mrmr.json'), 'r'))\n",
    "# ig = pickle.load(open(join(SOMEWHERE, 'mdd_svm_infogain_10.json'), 'r'))\n",
    "\n",
    "chi2 = pickle.load(open(join(SOMEWHERE, FILE1), 'r'))\n",
    "ig = pickle.load(open(join(SOMEWHERE, FILE2), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000, 200000, 100, 5000, 485577, 10, 50000, 1000, 50, 500, 10000]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 100, 500, 1000, 5000, 10000, 50000, 100000, 200000, 485577]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ig.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robust_comb = []\n",
    "probes = []\n",
    "for size in [10, 100, 500, 1000, 5000, 10000, 50000]:#, 1000]:\n",
    "#     union = anova[size]['union'] | mrmr[size]['union'] | ig[size]['union']\n",
    "#     inter = anova[size]['inter'] & mrmr[size]['inter'] & ig[size]['inter']\n",
    "    union = chi2[size]['union'] | ig[size]['union']\n",
    "    inter = chi2[size]['inter'] & ig[size]['inter']\n",
    "    probes.append(inter)\n",
    "#     robust_comb[size]['union'] = len(union)\n",
    "#     robust_comb[size]['inter'] = len(inter)\n",
    "    robust_comb.append({'size': size, 'union': len(union), 'inter': len(inter)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'cg08639402', u'cg18865796', u'cg07930620', u'cg04193083', u'cg21604516', u'cg11450715', u'cg04529658', u'cg10233639', u'cg02214188', u'cg02466933', u'cg24088775', u'cg09789536', u'cg18641876', u'cg14993530', u'cg00306426', u'cg17847344', u'cg07450219', u'cg13042636']\n",
      "cg08639402\n",
      "cg18865796\n",
      "cg07930620\n",
      "cg04193083\n",
      "cg21604516\n",
      "cg11450715\n",
      "cg04529658\n",
      "cg10233639\n",
      "cg02214188\n",
      "cg02466933\n",
      "cg24088775\n",
      "cg09789536\n",
      "cg18641876\n",
      "cg14993530\n",
      "cg00306426\n",
      "cg17847344\n",
      "cg07450219\n",
      "cg13042636\n"
     ]
    }
   ],
   "source": [
    "print(list(probes[5]))\n",
    "for p in probes[5]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "probes_flatten = []\n",
    "for p in probes:\n",
    "    probes_flatten.extend(list(p))\n",
    "print(len(probes_flatten))\n",
    "print(len(set(probes_flatten)))\n",
    "with open(join(SOMEWHERE, 'probes.txt'), 'w') as f:\n",
    "    for p in probes_flatten:\n",
    "        f.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inter</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>345</td>\n",
       "      <td>234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>18</td>\n",
       "      <td>67818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>4</td>\n",
       "      <td>37133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       inter   union\n",
       "size                \n",
       "50000    345  234286\n",
       "10000     18   67818\n",
       "5000       4   37133\n",
       "1000       0    8550\n",
       "500        0    4549\n",
       "100        0     970\n",
       "10         0     108"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = pd.DataFrame(robust_comb)\n",
    "foo = foo.set_index('size')\n",
    "foo = foo.iloc[::-1]\n",
    "foo_latex = foo.to_latex(na_rep=' ')\n",
    "foo_latex = process_latex(foo_latex, remove_lines=r'^size*')\n",
    "foo_latex = my_replace(foo_latex, src='inter', dst=r'$\\bm{\\cap}$', effects='c')\n",
    "foo_latex = my_replace(foo_latex, src='union', dst=r'$\\bm{\\cup}$', effects='c')\n",
    "save_table(foo_latex, 'ad_robust_comb.tex')\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AD Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EC+EN+chi2, FC+SVM+IG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1 31\n",
      "36 2 34\n",
      "370 3 357\n",
      "423 4 409\n",
      "458 5 443\n",
      "0:12:44.303732\n",
      "760 5 745\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "result_files = glob(join(RESULTS_PATH, '*_*.json'))\n",
    "result_files = [x for x in result_files if os.path.basename(x).startswith(('anova', 'infogain', 'rfe', 'chi2', 'mrmr'))]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# clf = 'svm'\n",
    "# filter_ = 'anova'\n",
    "# data = MDD\n",
    "# target = 'stress'\n",
    "\n",
    "constraints = [('clf', 'en'), ('filter', 'chi2'), ('data', EPI), ('tissue', EC)]\n",
    "keyby = ['n_features']\n",
    "i = 0\n",
    "no_clf = 0\n",
    "no_cond = 0\n",
    "results = defaultdict(list)\n",
    "\n",
    "d0 = datetime.now()\n",
    "for f in result_files:\n",
    "    i += 1\n",
    "    exp_id = f.split('_')[-1].rstrip('.json')\n",
    "    try:\n",
    "        d = json.load(open(join(RESULTS_PATH, f), 'r'))\n",
    "    except ValueError as e:\n",
    "        if os.path.getsize(f) == 0:\n",
    "            e = 'File size is 0. Removing.'\n",
    "            os.remove(f)\n",
    "        print('{} -> {}'.format(f, e))\n",
    "        os.remove(f)\n",
    "    base = {'exp_id': exp_id}\n",
    "    left = []\n",
    "    for k, v in d.items():\n",
    "        if k != 'experiments':\n",
    "            base[k] = v\n",
    "    if os.path.basename(f).startswith('mrmr'):\n",
    "        base['filter'] = 'mrmr'\n",
    "    elif os.path.basename(f).startswith('rfe'):\n",
    "        base['filter'] = 'rfe'\n",
    "  \n",
    "    if 'clf' not in base:\n",
    "        no_clf += 1\n",
    "        print(i, no_clf, no_cond)\n",
    "        continue\n",
    "        \n",
    "    if not all(base[k] == v for k, v in constraints):\n",
    "        no_cond += 1\n",
    "        continue\n",
    "        \n",
    "    for exp in d['experiments']:\n",
    "        it = exp['iteration']\n",
    "        if 'subsets' not in exp:\n",
    "            print('{} -> Field \"subsets\" not found.'.format(f))\n",
    "            continue\n",
    "        for s in exp['subsets']:\n",
    "            if 'n_features' not in s:\n",
    "                s['n_features'] = len(s['features'])\n",
    "            key = tuple(base[x] if x in base else s[x] for x in keyby)\n",
    "            results[key].append(set(s['features']))\n",
    "\n",
    "print(datetime.now() - d0)\n",
    "print(i, no_clf, no_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
