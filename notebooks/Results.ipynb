{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmourit/Documents/0project/MScThesis/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('Current directory:', os.getcwd())\n",
    "import sys\n",
    "from glob import glob\n",
    "import zipfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = os.path.expanduser('~/Documents/0project/bucket/results')\n",
    "result_file = 'result_*.json'\n",
    "block_file = 'results_block_*.json'\n",
    "zipped_file = 'zipped_results.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1001443862915039"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(os.path.getsize(f) / 1024 / 1024 for f in glob(os.path.join(results_path, result_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = glob(os.path.join(results_path, 'result?_*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'classifier',\n",
       " u'cross_val.n_folds',\n",
       " u'cross_val.shuffle',\n",
       " u'cross_val.type',\n",
       " u'data',\n",
       " u'experiment_id',\n",
       " u'pca.n_components',\n",
       " u'results.accuracy.mean',\n",
       " u'results.accuracy.scores',\n",
       " u'results.accuracy.std',\n",
       " u'results.time',\n",
       " u'split.n_iter',\n",
       " u'split.test_size',\n",
       " u'split.type',\n",
       " u'std_select.n_feat',\n",
       " u'target',\n",
       " u'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _extract_fields(d, path):\n",
    "    fields = set()\n",
    "    for k in d:\n",
    "        if isinstance(d[k], dict):\n",
    "            fields |= _extract_fields(d[k], path + k + '.')\n",
    "        else:\n",
    "            fields.add(path + k)\n",
    "    return fields\n",
    "\n",
    "fields = set()\n",
    "for f in files:\n",
    "    results = json.load(open(f, 'rb'))\n",
    "    if isinstance(results, dict):\n",
    "        results = [results]\n",
    "    for experiment in results:\n",
    "        fields |= _extract_fields(experiment, '')\n",
    "\n",
    "sorted(fields)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Queue import Queue\n",
    "def extract_json_fields(document):\n",
    "    q = Queue()\n",
    "    if isinstance(document, list):\n",
    "        for d in document:\n",
    "            q.put(('', d))\n",
    "    elif isinstance(document, dict):\n",
    "        q.put(document)\n",
    "    else:\n",
    "        raise ValueError(\"Document doesn't have a valid format.\")\n",
    "\n",
    "    fields = set()\n",
    "    while not q.empty():\n",
    "        prefix, d = q.get()\n",
    "        if isinstance(d, list):\n",
    "            for dd in d:\n",
    "                q.put((prefix + '[' if prefix else '', dd))\n",
    "        elif isinstance(d, dict):\n",
    "            for key in d:\n",
    "                q.put((prefix + '.' + key if prefix else key, d[key]))\n",
    "        else:\n",
    "            fields.add(prefix)\n",
    "\n",
    "    return sorted(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/25 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'clf',\n",
       " u'data',\n",
       " u'data_path',\n",
       " u'experiments[.iteration',\n",
       " u'experiments[.scores[',\n",
       " u'experiments[.subsets[.best_params.C',\n",
       " u'experiments[.subsets[.best_params.alpha',\n",
       " u'experiments[.subsets[.best_params.l1_ratio',\n",
       " u'experiments[.subsets[.features[',\n",
       " u'experiments[.subsets[.n_features',\n",
       " u'experiments[.subsets[.test.y_pred[',\n",
       " u'experiments[.subsets[.test.y_true[',\n",
       " u'experiments[.subsets[.train.y_pred[',\n",
       " u'experiments[.subsets[.train.y_true[',\n",
       " u'experiments[.train_samples_idx[',\n",
       " u'experiments[.train_samples_label[',\n",
       " u'filter',\n",
       " u'n_folds',\n",
       " u'n_iter',\n",
       " u'results_path',\n",
       " u'start_time',\n",
       " u'target',\n",
       " u'test_size',\n",
       " u'tissue',\n",
       " u'verbose']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(os.path.join(results_path, 'anova_*.json'))\n",
    "document = []\n",
    "error = 0\n",
    "total = 0\n",
    "for f in files:\n",
    "    try:\n",
    "        document.append(json.load(open(f, 'rb')))\n",
    "    except:\n",
    "        error += 1\n",
    "    total += 1\n",
    "print('{}/{} errors.'.format(error, total))\n",
    "extract_json_fields(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([(u'mdd_raw', None, u'stress', u'anova'), (u'mdd', None, u'stress', u'anova'), (u'mdd_raw37', None, u'stress', u'anova'), (u'mdd', None, u'drug', u'anova')])\n"
     ]
    }
   ],
   "source": [
    "combinations = set()\n",
    "for d in document:\n",
    "    if 'clf' not in d:\n",
    "        continue\n",
    "    combinations.add((d['data'], d['tissue'], d['target'], d['filter']))\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdd None stress anova\n",
      "37231 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "30000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "20000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "10000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 9000 0.53$\\pm$0.00 0.53$\\pm$0.00 \n",
      " 8000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 7000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 6000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 5000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 4000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 3000 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      " 2000 0.53$\\pm$0.00 0.53$\\pm$0.00 \n",
      " 1000 0.73$\\pm$0.00 0.73$\\pm$0.00 \n",
      "  900 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  800 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  700 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  600 0.53$\\pm$0.00 0.53$\\pm$0.00 \n",
      "  500 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  400 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  300 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  200 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "  100 0.67$\\pm$0.00 0.67$\\pm$0.00 \n",
      "   90 0.53$\\pm$0.00 0.53$\\pm$0.00 \n",
      "   80 0.40$\\pm$0.00 0.40$\\pm$0.00 \n",
      "   70 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "   60 0.40$\\pm$0.00 0.40$\\pm$0.00 \n",
      "   50 0.40$\\pm$0.00 0.40$\\pm$0.00 \n",
      "   40 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "   30 0.33$\\pm$0.00 0.33$\\pm$0.00 \n",
      "   20 0.53$\\pm$0.00 0.53$\\pm$0.00 \n",
      "   10 0.33$\\pm$0.00 0.33$\\pm$0.00 \n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "data, tissue, target, filter_ = combinations.pop()\n",
    "for d in document:\n",
    "    if (d['data'] == data\n",
    "        and d['tissue'] == tissue\n",
    "        and d['target'] == target\n",
    "        and d['filter'] == filter_\n",
    "        and 'clf' in d):\n",
    "        for subset in experiment['subsets']:\n",
    "            size = len(subset['features'])\n",
    "            if size not in scores:\n",
    "                scores[size] = defaultdict(list)\n",
    "            y_true = subset['test']['y_true']\n",
    "            y_pred = subset['test']['y_pred']\n",
    "            score = accuracy_score(y_true, y_pred)\n",
    "            scores[size][d['clf']].append(score)\n",
    "print(data, tissue, target, filter_)\n",
    "clfs = sorted({clf for clf in scores[size] for size in scores})\n",
    "for size in sorted(scores.keys(), reverse=True):\n",
    "    s = '{:5d} '.format(size)\n",
    "    for clf in clfs:\n",
    "        s += '{:1.2f}$\\pm${:1.2f} '.format(np.mean(scores[size][clf]), np.std(scores[size][clf]))\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, tissue, target, filter_, clf = combinations[0]\n",
    "for d in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "scores = defaultdict(list)\n",
    "for d in document:\n",
    "    for experiment in d['experiments']:\n",
    "#         print(experiment.keys())\n",
    "        if 'subsets' not in experiment:\n",
    "            continue\n",
    "        for subset in experiment['subsets']:\n",
    "            size = len(subset['features'])\n",
    "            y_true = subset['test']['y_true']\n",
    "            y_pred = subset['test']['y_pred']\n",
    "            score = accuracy_score(y_true, y_pred)\n",
    "            scores[(d['data'], d['target'], d['filter'], d['clf'], size)].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 ['0.35+/-0.04', '0.86+/-0.08']\n",
      "900 ['0.87+/-0.06', '0.33+/-0.03', '0.48+/-0.13', '0.87+/-0.11', '0.91+/-0.06', '0.43+/-0.14', '0.39+/-0.09']\n",
      "5000 ['0.33+/-0.00', '0.89+/-0.07', '0.91+/-0.07', '0.36+/-0.03', '0.33+/-0.00', '0.33+/-0.00', '0.87+/-0.08']\n",
      "10 ['0.39+/-0.10', '0.77+/-0.12', '0.36+/-0.07', '0.49+/-0.13', '0.74+/-0.07', '0.44+/-0.16', '0.81+/-0.11']\n",
      "10000 ['0.89+/-0.07', '0.36+/-0.04', '0.34+/-0.03', '0.91+/-0.06', '0.87+/-0.08', '0.35+/-0.04', '0.37+/-0.07']\n",
      "7000 ['0.89+/-0.07', '0.91+/-0.07', '0.34+/-0.03', '0.36+/-0.06', '0.41+/-0.11', '0.89+/-0.05', '0.34+/-0.02']\n",
      "20 ['0.87+/-0.10', '0.41+/-0.10', '0.82+/-0.08', '0.34+/-0.03', '0.83+/-0.09', '0.44+/-0.16', '0.39+/-0.08']\n",
      "30 ['0.84+/-0.08', '0.85+/-0.10', '0.42+/-0.11', '0.34+/-0.04', '0.39+/-0.11', '0.36+/-0.06', '0.88+/-0.06']\n",
      "20000 ['0.87+/-0.08', '0.35+/-0.02', '0.86+/-0.09', '0.35+/-0.03', '0.87+/-0.06', '0.34+/-0.02', '0.37+/-0.07']\n",
      "2000 ['0.87+/-0.08', '0.33+/-0.03', '0.35+/-0.06', '0.91+/-0.06', '0.33+/-0.00', '0.89+/-0.07', '0.35+/-0.06']\n",
      "9000 ['0.89+/-0.07', '0.90+/-0.07', '0.35+/-0.03', '0.37+/-0.07', '0.37+/-0.07', '0.34+/-0.04', '0.90+/-0.06']\n",
      "300 ['0.87+/-0.06', '0.32+/-0.04', '0.91+/-0.05', '0.90+/-0.06', '0.37+/-0.10', '0.33+/-0.00', '0.35+/-0.04']\n",
      "45101 ['0.35+/-0.08', '0.85+/-0.08']\n",
      "30000 ['0.35+/-0.03', '0.33+/-0.00', '0.34+/-0.02', '0.34+/-0.03', '0.87+/-0.10', '0.85+/-0.09', '0.85+/-0.10']\n",
      "50 ['0.88+/-0.07', '0.83+/-0.06', '0.88+/-0.12', '0.49+/-0.20', '0.34+/-0.03', '0.48+/-0.14', '0.45+/-0.13']\n",
      "3000 ['0.89+/-0.06', '0.33+/-0.00', '0.37+/-0.08', '0.91+/-0.07', '0.34+/-0.03', '0.33+/-0.02', '0.86+/-0.09']\n",
      "60 ['0.43+/-0.12', '0.87+/-0.09', '0.34+/-0.03', '0.41+/-0.08', '0.87+/-0.08', '0.90+/-0.05', '0.40+/-0.12']\n",
      "8000 ['0.37+/-0.10', '0.90+/-0.07', '0.90+/-0.06', '0.88+/-0.08', '0.35+/-0.02', '0.35+/-0.04', '0.38+/-0.07']\n",
      "4000 ['0.31+/-0.07', '0.34+/-0.02', '0.87+/-0.09', '0.91+/-0.06', '0.89+/-0.06', '0.35+/-0.04', '0.35+/-0.04']\n",
      "70 ['0.86+/-0.06', '0.35+/-0.06', '0.88+/-0.07', '0.45+/-0.14', '0.54+/-0.19', '0.89+/-0.06', '0.43+/-0.13']\n",
      "200 ['0.91+/-0.07', '0.36+/-0.05', '0.33+/-0.00', '0.35+/-0.06', '0.33+/-0.00', '0.88+/-0.06', '0.93+/-0.06']\n",
      "80 ['0.44+/-0.16', '0.87+/-0.08', '0.87+/-0.08', '0.91+/-0.07', '0.46+/-0.13', '0.34+/-0.04', '0.59+/-0.18']\n",
      "600 ['0.39+/-0.07', '0.36+/-0.05', '0.87+/-0.08', '0.89+/-0.10', '0.92+/-0.05', '0.34+/-0.03', '0.41+/-0.18']\n",
      "90 ['0.55+/-0.16', '0.85+/-0.09', '0.93+/-0.06', '0.38+/-0.10', '0.49+/-0.15', '0.47+/-0.19', '0.91+/-0.06']\n",
      "800 ['0.88+/-0.10', '0.41+/-0.09', '0.41+/-0.10', '0.45+/-0.14', '0.34+/-0.04', '0.91+/-0.06', '0.87+/-0.07']\n",
      "400 ['0.34+/-0.03', '0.38+/-0.09', '0.90+/-0.05', '0.88+/-0.06', '0.92+/-0.08', '0.33+/-0.00', '0.34+/-0.02']\n",
      "100 ['0.36+/-0.06', '0.90+/-0.09', '0.45+/-0.16', '0.56+/-0.21', '0.51+/-0.20', '0.89+/-0.06', '0.86+/-0.08']\n",
      "1000 ['0.36+/-0.07', '0.87+/-0.11', '0.45+/-0.16', '0.43+/-0.13', '0.88+/-0.07', '0.52+/-0.17', '0.91+/-0.06']\n",
      "700 ['0.46+/-0.12', '0.89+/-0.09', '0.87+/-0.07', '0.45+/-0.11', '0.93+/-0.06', '0.35+/-0.02', '0.43+/-0.10']\n",
      "37231 ['0.86+/-0.09', '0.34+/-0.02', '0.34+/-0.03', '0.33+/-0.00', '0.86+/-0.09']\n",
      "6000 ['0.38+/-0.08', '0.33+/-0.00', '0.89+/-0.07', '0.91+/-0.05', '0.35+/-0.04', '0.36+/-0.00', '0.89+/-0.07']\n",
      "40 ['0.34+/-0.03', '0.85+/-0.11', '0.85+/-0.08', '0.88+/-0.09', '0.38+/-0.08', '0.39+/-0.10', '0.40+/-0.10']\n",
      "500 ['0.87+/-0.06', '0.32+/-0.04', '0.91+/-0.06', '0.34+/-0.02', '0.94+/-0.06', '0.41+/-0.10', '0.36+/-0.08']\n"
     ]
    }
   ],
   "source": [
    "size_score = defaultdict(list)\n",
    "for k in scores:\n",
    "    data, target, filter_, clf, size = k\n",
    "    foo = '{:1.2f}+/-{:1.2f}'.format(np.mean(scores[k]), np.std(scores[k]))\n",
    "    size_score[size].append(foo)\n",
    "for k in size_score:\n",
    "    print(k, size_score[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
